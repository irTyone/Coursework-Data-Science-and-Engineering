import json
import argparse
from typing import Dict, List, Set


# =========================
# 1. åŠ è½½åœç”¨è¯
# =========================
def load_stopwords(stopword_file: str) -> Set[str]:
    """
    åŠ è½½åœç”¨è¯è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªè¯ï¼‰
    """
    with open(stopword_file, "r", encoding="utf-8") as f:
        return set(w.strip() for w in f if w.strip())


# =========================
# 2. TinyDB è¯è¡¨ â†’ JSON
# =========================
def vocab_2_json(
    tinydb_file: str,
    output_file: str,
    stopwords: Set[str] | None = None
) -> Dict[str, str]:
    """
    TinyDB æ ¼å¼è¯è¡¨ â†’ æ™®é€š JSON {word_id: word}
    åŒæ—¶è¿‡æ»¤åœç”¨è¯
    """
    with open(tinydb_file, "r", encoding="utf-8") as f:
        vocab_tiny = json.load(f)

    vocab_new = {}

    for word_id, info in vocab_tiny["_default"].items():
        word = info["word"]

        # åœç”¨è¯è¿‡æ»¤
        if stopwords and word in stopwords:
            continue

        vocab_new[word_id] = word

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(vocab_new, f, ensure_ascii=False, indent=2)

    print(f"[OK] è¯è¡¨ä¿å­˜åˆ° {output_file}ï¼ˆä¿ç•™ {len(vocab_new)} ä¸ªè¯ï¼‰")
    return vocab_new


# =========================
# 3. TinyDB æ–‡æ¡£è¯é¢‘ â†’ JSON
# =========================
def freq_2_json(
    tinydb_file: str,
    output_file: str,
    valid_vocab_ids: Set[str]
) -> List[Dict[str, int]]:
    """
    TinyDB æ ¼å¼æ–‡ç« è¯é¢‘ â†’ åˆ—è¡¨å½¢å¼
    [{word_id: freq, ...}, ...]
    ä»…ä¿ç•™ vocab ä¸­å­˜åœ¨çš„è¯
    """
    with open(tinydb_file, "r", encoding="utf-8") as f:
        docs_tiny = json.load(f)

    docs_new = []

    for doc_info in docs_tiny["_default"].values():
        words = doc_info.get("words", {})

        filtered = {
            word_id: freq
            for word_id, freq in words.items()
            if word_id in valid_vocab_ids and freq > 0
        }

        if filtered:
            docs_new.append(filtered)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(docs_new, f, ensure_ascii=False, indent=2)

    print(f"[OK] æ–‡æ¡£è¯é¢‘ä¿å­˜åˆ° {output_file}ï¼ˆå…± {len(docs_new)} ç¯‡ï¼‰")
    return docs_new


# =========================
# 4. ä¸»å…¥å£
# =========================
def main():
    parser = argparse.ArgumentParser(
        description="TinyDB â†’ LDA/OLDA å¯ç”¨ JSONï¼ˆå«åœç”¨è¯è¿‡æ»¤ï¼‰"
    )
    parser.add_argument("--vocab_tinydb", required=True, help="TinyDB è¯è¡¨ JSON")
    parser.add_argument("--doc_tinydb", required=True, help="TinyDB æ–‡æ¡£è¯é¢‘ JSON")
    parser.add_argument("--stopwords", required=True, help="åœç”¨è¯ txt æ–‡ä»¶")
    parser.add_argument("--out_dir", required=True, help="è¾“å‡ºç›®å½•")

    args = parser.parse_args()

    vocab_out = f"{args.out_dir}/vocab.json"
    freq_out = f"{args.out_dir}/freq.json"

    # 1. åŠ è½½åœç”¨è¯
    stopwords = load_stopwords(args.stopwords)
    print(f"[INFO] åŠ è½½åœç”¨è¯ {len(stopwords)} ä¸ª")

    # 2. å¤„ç†è¯è¡¨
    vocab = vocab_2_json(
        args.vocab_tinydb,
        vocab_out,
        stopwords=stopwords
    )

    # 3. å¤„ç†æ–‡æ¡£è¯é¢‘ï¼ˆä¸¥æ ¼å¯¹é½è¯è¡¨ï¼‰
    valid_vocab_ids = set(vocab.keys())
    freq_2_json(
        args.doc_tinydb,
        freq_out,
        valid_vocab_ids=valid_vocab_ids
    )

    print("\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼Œå¯ç›´æ¥ç”¨äº LDA / OLDA è®­ç»ƒ")


if __name__ == "__main__":
    main()